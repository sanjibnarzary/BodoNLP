{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "with open('../trained_models/pickles/bodo_tagged_pickl.pkl', 'rb') as f:\n",
    "    u = pickle._Unpickler(f) #UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n",
    "    u.encoding = 'utf-8'\n",
    "    X_train, Y_train, word2int, int2word, tag2int, int2tag = u.load()\n",
    "\n",
    "    del X_train\n",
    "    del Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'बेनि जाउनाव बोहैथि बोसोरनि गिबि ए ति पि माष्टार्स सिरिस बिमुं मोननो हानायनि खाबुखौ लानो हादों ।'.split()\n",
    "#बेनि/DM_DMD जाउनाव/N_NN बोहैथि/N_NN बोसोरनि/N_NN गिबि/JJ ए/N_NNP ति/N_NNP पि/N_NNP माष्टार्स/N_NNP \n",
    "#सिरिस/N_NNP बिमुं/N_NN मोननो/V_VM हानायनि/N_NN \n",
    "#खाबुखौ/N_NN लानो/V_VM हादों/V_VM ।/RD_PUNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence is  ['बेनि', 'जाउनाव', 'बोहैथि', 'बोसोरनि', 'गिबि', 'ए', 'ति', 'पि', 'माष्टार्स', 'सिरिस', 'बिमुं', 'मोननो', 'हानायनि', 'खाबुखौ', 'लानो', 'हादों', '।']\n",
      "The tokenized sentence is  [[52580 59547 40665 60376 20550 41303 25215 18770 43851 12574 22236 21653\n",
      "  12522 35887 25479   285 17421]]\n",
      "The padded tokenized sentence is  [[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0 52580\n",
      "  59547 40665 60376 20550 41303 25215 18770 43851 12574 22236 21653 12522\n",
      "  35887 25479   285 17421]]\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentence = []\n",
    "\n",
    "for word in sentence:\n",
    "        tokenized_sentence.append(word2int[word])\n",
    "\n",
    "tokenized_sentence = np.asarray([tokenized_sentence])\n",
    "padded_tokenized_sentence = pad_sequences(tokenized_sentence, maxlen=100)\n",
    "\n",
    "print('The sentence is ', sentence)\n",
    "print('The tokenized sentence is ',tokenized_sentence)\n",
    "print('The padded tokenized sentence is ', padded_tokenized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 37)\n"
     ]
    }
   ],
   "source": [
    "model = load_model('../trained_models/pos/bodo_lstm_pos.h5')\n",
    "\n",
    "prediction = model.predict(padded_tokenized_sentence)\n",
    "\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RD_ECH': 1, 'RD_SYM': 2, 'V_VM': 3, 'RP_RPD': 4, 'JJ': 5, 'RP_NEG': 6, 'RD_RDF': 7, 'RD_UNK': 8, 'N_NNP': 9, 'N_NNV': 10, 'RP_INTF': 11, 'N_NST': 12, 'RB': 13, 'N_NN': 14, 'RP_INJ': 23, 'QT_QTO': 16, 'QT_QTF': 18, 'CC_CCD': 17, 'QT_QTC': 19, 'DM_DMR': 24, 'V_VM_VF': 21, 'CC_CCS': 22, 'DM_DMQ': 15, 'PR_PRL': 20, 'PR_PRI': 25, 'V_VAUX': 26, 'PR_PRF': 27, 'PR_PRC': 28, 'V_VM_VNF': 29, 'RD_PUNC': 30, 'DM_DMD': 31, 'V_VAUX_VF': 32, 'DM_DMI': 33, 'PSP': 34, 'PR_PRQ': 35, 'PR_PRP': 36}\n"
     ]
    }
   ],
   "source": [
    "print(tag2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged Sentence:\tबेनि/DM_DMD जाउनाव/N_NST बोहैथि/N_NN बोसोरनि/N_NN गिबि/N_NST ए/RD_UNK ति/RD_UNK पि/RD_UNK माष्टार्स/RD_UNK सिरिस/N_NNP बिमुं/N_NN मोननो/V_VM हानायनि/V_VM खाबुखौ/N_NN लानो/V_VM हादों/V_VM ।/RD_PUNC \n",
      "\n",
      "Original Sentence:\tबेनि/DM_DMD जाउनाव/N_NN बोहैथि/N_NN बोसोरनि/N_NN गिबि/JJ ए/N_NNP ति/N_NNP पि/N_NNP माष्टार्स/N_NNP सिरिस/N_NNP बिमुं/N_NN मोननो/V_VM हानायनि/N_NN खाबुखौ/N_NN लानो/V_VM हादों/V_VM ।/RD_PUNC\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "#print(len(sentence))\n",
    "tagged_sent = ''\n",
    "for i, pred in enumerate(prediction[0]):\n",
    "        p = np.argmax(pred)\n",
    "        #print(p)\n",
    "        if p == 0:\n",
    "            pass\n",
    "        #elif i == len(sentence):\n",
    "           # break\n",
    "        else:\n",
    "            #print(sentence[index], ' : ', int2tag[p])\n",
    "            tagged_sent += sentence[index]+'/'+int2tag[p]+' '\n",
    "            index +=1\n",
    "        \n",
    "        try:\n",
    "            print(sentence[i], ' : ', int2tag[np.argmax(pred)])\n",
    "        except:\n",
    "            pass\n",
    "                # print('NA')\n",
    "\n",
    "original_sent = \"बेनि/DM_DMD जाउनाव/N_NN बोहैथि/N_NN बोसोरनि/N_NN गिबि/JJ ए/N_NNP ति/N_NNP पि/N_NNP माष्टार्स/N_NNP सिरिस/N_NNP बिमुं/N_NN मोननो/V_VM हानायनि/N_NN खाबुखौ/N_NN लानो/V_VM हादों/V_VM ।/RD_PUNC\"\n",
    "print('Tagged Sentence:\\t'+tagged_sent+\"\\n\")\n",
    "print(\"Original Sentence:\\t\"+original_sent+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#बेनि/DM_DMD जाउनाव/N_NN बोहैथि/N_NN बोसोरनि/N_NN गिबि/JJ ए/N_NNP ति/N_NNP पि/N_NNP माष्टार्स/N_NNP \n",
    "#सिरिस/N_NNP बिमुं/N_NN मोननो/V_VM हानायनि/N_NN \n",
    "#खाबुखौ/N_NN लानो/V_VM हादों/V_VM ।/RD_PUNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
