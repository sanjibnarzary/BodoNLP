{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install torch numpy tqdm scipy termcolor gast==0.2.2 fairseq"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!wget http://get.alayaran.com/bodo_data/brx_mlm.zip\n",
    "!unzip brx_mlm.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading archive file /home/sn/PhD_Dec_2019_Onwards/Experiments/NeuralLM/bodo_nlp_gthub/language_models/brx-mlm\n",
      "| dictionary: 31312 types\n",
      "Namespace(activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_input_cutoff=None, adaptive_input_factor=4, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, add_bos_token=False, all_gather_list_size=16384, arch='transformer_lm', attention_dropout=0.0, best_checkpoint_metric='loss', bpe='subword_nmt', bpe_codes='/home/sn/PhD_Dec_2019_Onwards/Experiments/NeuralLM/bodo_nlp_gthub/language_models/brx-mlm/bodo_subword_32k_code', bpe_separator='@@', broadcast_buffers=False, bucket_cap_mb=25, char_embedder_highway_layers=2, character_embedding_dim=4, character_embeddings=False, character_filters='[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', clip_norm=0.0, cpu=False, criterion='cross_entropy', curriculum=0, data='/home/sn/PhD_Dec_2019_Onwards/Experiments/NeuralLM/bodo_nlp_gthub/language_models/brx-mlm', dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method='tcp://localhost:11053', distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=2, dropout=0.1, empty_cache_freq=0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, layernorm_embedding=False, log_format='tqdm', log_interval=1000, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_sentences=None, max_sentences_valid=None, max_target_positions=512, max_tokens=2048, max_tokens_valid=2048, max_update=50000, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, moses_no_dash_splits=False, moses_no_escape=False, no_decoder_final_norm=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', output_dictionary_size=-1, past_target=False, patience=-1, raw_text=False, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', sample_break_mode='none', save_dir='checkpoints/transformer_brx-mlm', save_interval=1, save_interval_updates=0, seed=1, self_target=False, sentence_avg=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, task='language_modeling', tensorboard_logdir='', threshold_loss_scale=None, tie_adaptive_proj=False, tie_adaptive_weights=False, tokenizer='moses', tokens_per_sample=512, train_subset='train', truncate_sequence=False, update_freq=[16], use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.01)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'जिउ थाजासिम आरो मिथिंगा सलʼ हा-मिथिंगा गिबि-मिथिंगा गेजेरजों फोरमायथिनाय दं ।'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The same interface can be used with custom models as well\n",
    "MODEL_PATH='/path/to/language_models/brx-mlm'\n",
    "from fairseq.models.transformer_lm import TransformerLanguageModel\n",
    "ckpt=MODEL_PATH + \"/checkpoint_last.pt\"\n",
    "model_path=MODEL_PATH\n",
    "bpe_code = MODEL_PATH+\"/bodo_subword_32k_code\"\n",
    "custom_lm = TransformerLanguageModel.from_pretrained(model_path, ckpt, tokenizer='moses', bpe='subword_nmt', bpe_codes=bpe_code)\n",
    "custom_lm.sample('जिउ थाजासिम', beam=5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "epoch 1854 | valid on 'valid' subset | loss 34.425 | ppl 2.30598e+10 | wps 160483 | wpb 4089 | bsz 8 | num_updates 49966 | best_loss 11.67\n",
    "2020-02-02 07:42:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/transformer_brx-mlm/checkpoint1854.pt (epoch 1854 @ 49966 updates, score 34.425) (writing took 3.33485838699562 seconds)\n",
    "epoch 1855 | loss 0.028 | ppl 1.02 | wps 59521 | ups 0.93 | wpb 63990.7 | bsz 125 | num_updates 49993 | lr 0.000141431 | gnorm 0.138 | clip 0 | oom 0 | loss_scale 256 | train_wall 23 | wall 48423\n",
    "epoch 1855 | loss 0.028 | ppl 1.02 | wps 59521 | ups 0.93 | wpb 63990.7 | bsz 125 | num_updates 49993 | lr 0.000141431 | gnorm 0.138 | clip 0 | oom 0 | loss_scale 256 | train_wall 21 | wall 48423\n",
    "epoch 1855 | valid on 'valid' subset | loss 34.491 | ppl 2.41489e+10 | wps 161497 | wpb 4089 | bsz 8 | num_updates 49993 | best_loss 11.67\n",
    "epoch 1856:   0%|                                                                                            | 0/27 [00:00<?, ?it/s]epoch 1855 | valid on 'valid' subset | loss 34.491 | ppl 2.41489e+10 | wps 160647 | wpb 4089 | bsz 8 | num_updates 49993 | best_loss 11.67\n",
    "2020-02-02 07:42:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/transformer_brx-mlm/checkpoint1855.pt (epoch 1855 @ 49993 updates, score 34.491) (writing took 3.1901714359992184 seconds)\n",
    "epoch 1856 | loss 0.027 | ppl 1.019 | wps 37867.6 | ups 0.58 | wpb 65500 | bsz 128 | num_updates 50000 | lr 0.000141421 | gnorm 0.133 | clip 0 | oom 0 | loss_scale 256 | train_wall 8 | wall 48435\n",
    "epoch 1856 | loss 0.027 | ppl 1.019 | wps 37844.5 | ups 0.58 | wpb 65500 | bsz 128 | num_updates 50000 | lr 0.000141421 | gnorm 0.133 | clip 0 | oom 0 | loss_scale 256 | train_wall 6 | wall 48435\n",
    "epoch 1856 | valid on 'valid' subset | loss 34.555 | ppl 2.5234e+10 | wps 158320 | wpb 4089 | bsz 8 | num_updates 50000 | best_loss 11.67\n",
    "epoch 1856 | valid on 'valid' subset | loss 34.555 | ppl 2.5234e+10 | wps 156910 | wpb 4089 | bsz 8 | num_updates 50000 | best_loss 11.67\n",
    "2020-02-02 07:42:51 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/transformer_brx-mlm/checkpoint_last.pt (epoch 1856 @ 50000 updates, score 34.555) (writing took 1.5825968279968947 seconds)\n",
    "2020-02-02 07:42:51 | INFO | fairseq_cli.train | done training in 48438.3 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAMA"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "python lama/eval_generation.py  --lm \"bert\" --bmd /tmp/bodo_bert_pretraining_output  --t \"नाथाय बे बादि गेजेर सानाव [MASK].\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
